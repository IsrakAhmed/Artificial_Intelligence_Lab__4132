{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design a simple DNN.\n",
    "### Use three hidden-layers of sizes 32, 64, and 128 and display the generated DNN with the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Flatten, Conv2D, MaxPooling2D, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN():\n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(InputLayer(shape=(784,)))\n",
    "\n",
    "  model.add(Dense(32, activation = 'relu'))\n",
    "\n",
    "  model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "  model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m25,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,681</span> (139.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,681\u001b[0m (139.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,681</span> (139.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,681\u001b[0m (139.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_1, built=True>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Deep Neural Network (DNN)?\n",
    "A Deep Neural Network (DNN) is a type of neural network that consists of multiple hidden layers between the input and output layers. These hidden layers allow the model to learn complex patterns and hierarchical representations from data.\n",
    "\n",
    "Deep refers to the number of layers. The more layers there are, the \"deeper\" the network.\n",
    "DNNs are used for supervised learning tasks such as classification, regression, and other pattern recognition tasks.\n",
    "\n",
    "## Components of a DNN\n",
    "### Input Layer:\n",
    "The input layer is where the data enters the network.\n",
    "It consists of neurons (nodes) that represent the features of your data. Each feature corresponds to one input node.\n",
    "Example: For an image with 784 pixels (28x28), the input layer would have 784 neurons, each corresponding to one pixel value.\n",
    "\n",
    "### Hidden Layers:\n",
    "Hidden layers are layers between the input and output layers.\n",
    "Each hidden layer consists of neurons that transform the input data through weighted connections and activation functions.\n",
    "The purpose of hidden layers is to capture complex patterns and relationships in the data.\n",
    "In a DNN, there are two or more hidden layers (the depth).\n",
    "\n",
    "### Output Layer:\n",
    "The output layer is where the final predictions are made.\n",
    "For classification tasks, the output layer contains one neuron per class. The activation function used here depends on the task:\n",
    "- Sigmoid for binary classification (1 output neuron).\n",
    "- Softmax for multiclass classification (one neuron per class).\n",
    "- Linear for regression tasks (1 output neuron).\n",
    "\n",
    "### Weights and Biases:\n",
    "Weights are learnable parameters that represent the strength of the connections between neurons.\n",
    "Biases are additional parameters that help shift the activation function, allowing the network to make predictions even when the inputs are zero.\n",
    "\n",
    "### Activation Functions:\n",
    "Activation functions introduce non-linearity to the network, allowing it to learn complex patterns. Without activation functions, the network would just be a linear transformation.\n",
    "Common activation functions:\n",
    "- ReLU (Rectified Linear Unit): The most popular activation function. It outputs the input directly if it's positive, otherwise, it outputs zero.\n",
    "- Sigmoid: Outputs a value between 0 and 1, typically used for binary classification.\n",
    "- Softmax: Used in the output layer for multiclass classification, outputs probabilities for each class.\n",
    "- Tanh (Hyperbolic Tangent): Similar to sigmoid but outputs values between -1 and 1.\n",
    "\n",
    "### Loss Function:\n",
    "The loss function measures how well the model's predictions match the actual values.\n",
    "During training, the model attempts to minimize this loss to improve performance.\n",
    "Common loss functions:\n",
    "- Mean Squared Error (MSE): Used for regression tasks.\n",
    "- Binary Cross-Entropy: Used for binary classification.\n",
    "- Categorical Cross-Entropy: Used for multiclass classification.\n",
    "\n",
    "### Optimizer:\n",
    "The optimizer adjusts the weights and biases of the network to minimize the loss function.\n",
    "It determines how the model learns during training.\n",
    "Common optimizers:\n",
    "- SGD (Stochastic Gradient Descent): A basic optimizer.\n",
    "- Adam: An adaptive optimizer that adjusts the learning rate for each parameter based on its past gradients.\n",
    "\n",
    "### Metrics:\n",
    "Metrics are used to evaluate the model's performance during training and testing.\n",
    "Common metrics:\n",
    "- Accuracy: Percentage of correct predictions (commonly used in classification).\n",
    "- Precision, Recall, F1-Score: Common in imbalanced classification tasks.\n",
    "\n",
    "\n",
    "\n",
    "## When Is an ANN Called a DNN?\n",
    "An Artificial Neural Network (ANN) is referred to as a Deep Neural Network (DNN) when it has two or more hidden layers in addition to the input and output layers. The distinction lies primarily in the depth of the network, which refers to the number of layers between the input and output layers.\n",
    "An ANN becomes a DNN when:\n",
    "\n",
    "- It has two or more hidden layers (layers that are neither input nor output layers).\n",
    "- These additional layers enable the network to learn more complex and hierarchical patterns in the data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
